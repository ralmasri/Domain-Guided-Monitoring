{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from pathlib import Path\n",
    "\n",
    "import cdt\n",
    "cdt.SETTINGS.rpath = \"/usr/bin/Rscript\"\n",
    "\n",
    "import pandas as pd\n",
    "from src.features import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating DRAIN clusters from log_df: 100%|██████████| 50/50 [00:00<00:00, 1938.70it/s]\n",
      "Generating DRAIN clusters from log_df: 100%|██████████| 50/50 [00:00<00:00, 1071.93it/s]\n",
      "Generating DRAIN clusters from log_df: 100%|██████████| 15/15 [00:00<00:00, 2758.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hostname</th>\n",
       "      <th>log_level</th>\n",
       "      <th>programname</th>\n",
       "      <th>python_module</th>\n",
       "      <th>http_status</th>\n",
       "      <th>http_method</th>\n",
       "      <th>@timestamp</th>\n",
       "      <th>fine_log_cluster_template</th>\n",
       "      <th>coarse_log_cluster_template</th>\n",
       "      <th>url_cluster_template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wally113</td>\n",
       "      <td></td>\n",
       "      <td>placement-api-access</td>\n",
       "      <td></td>\n",
       "      <td>200.0</td>\n",
       "      <td>GET</td>\n",
       "      <td>2019-11-19T17:00:05.000000000+01:00</td>\n",
       "      <td>19 nov 2019 17 * * 0100 get resource providers...</td>\n",
       "      <td>19 nov 2019 17 * * 0100 get resource providers...</td>\n",
       "      <td>resource providers 45bac5db-7b40-4922-ae54-fe7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wally113</td>\n",
       "      <td>INFO</td>\n",
       "      <td>neutron-server</td>\n",
       "      <td>neutron.wsgi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019-11-19T17:00:48.255000000+01:00</td>\n",
       "      <td>get v20 networks tenant id 99c2677b197747c9bd8...</td>\n",
       "      <td>get v20 networks tenant id 99c2677b197747c9bd8...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wally113</td>\n",
       "      <td>INFO</td>\n",
       "      <td>neutron-server</td>\n",
       "      <td>neutron.wsgi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019-11-19T17:00:48.274000000+01:00</td>\n",
       "      <td>get v20 networks shared true http 11 status 20...</td>\n",
       "      <td>get v20 networks shared true http 11 status 20...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wally113</td>\n",
       "      <td>INFO</td>\n",
       "      <td>neutron-server</td>\n",
       "      <td>neutron.wsgi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019-11-19T17:01:50.119000000+01:00</td>\n",
       "      <td>get v20 ports fields binding 3ahost id fields ...</td>\n",
       "      <td>get v20 ports fields binding 3ahost id fields ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wally113</td>\n",
       "      <td>INFO</td>\n",
       "      <td>neutron-server</td>\n",
       "      <td>neutron.wsgi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019-11-19T17:01:50.210000000+01:00</td>\n",
       "      <td>get v20 ports tenant id 99c2677b197747c9bd8bc0...</td>\n",
       "      <td>get v20 ports tenant id 99c2677b197747c9bd8bc0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hostname log_level           programname python_module http_status  \\\n",
       "0  wally113            placement-api-access                     200.0   \n",
       "1  wally113      INFO        neutron-server  neutron.wsgi               \n",
       "2  wally113      INFO        neutron-server  neutron.wsgi               \n",
       "3  wally113      INFO        neutron-server  neutron.wsgi               \n",
       "4  wally113      INFO        neutron-server  neutron.wsgi               \n",
       "\n",
       "  http_method                           @timestamp  \\\n",
       "0         GET  2019-11-19T17:00:05.000000000+01:00   \n",
       "1              2019-11-19T17:00:48.255000000+01:00   \n",
       "2              2019-11-19T17:00:48.274000000+01:00   \n",
       "3              2019-11-19T17:01:50.119000000+01:00   \n",
       "4              2019-11-19T17:01:50.210000000+01:00   \n",
       "\n",
       "                           fine_log_cluster_template  \\\n",
       "0  19 nov 2019 17 * * 0100 get resource providers...   \n",
       "1  get v20 networks tenant id 99c2677b197747c9bd8...   \n",
       "2  get v20 networks shared true http 11 status 20...   \n",
       "3  get v20 ports fields binding 3ahost id fields ...   \n",
       "4  get v20 ports tenant id 99c2677b197747c9bd8bc0...   \n",
       "\n",
       "                         coarse_log_cluster_template  \\\n",
       "0  19 nov 2019 17 * * 0100 get resource providers...   \n",
       "1  get v20 networks tenant id 99c2677b197747c9bd8...   \n",
       "2  get v20 networks shared true http 11 status 20...   \n",
       "3  get v20 ports fields binding 3ahost id fields ...   \n",
       "4  get v20 ports tenant id 99c2677b197747c9bd8bc0...   \n",
       "\n",
       "                                url_cluster_template  \n",
       "0  resource providers 45bac5db-7b40-4922-ae54-fe7...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('/home/ralmasri/projects/Thesis/Domain-Guided-Monitoring/data/')\n",
    "csv_path = data_path / \"logs_aggregated_concurrent.csv\"\n",
    "size = 50\n",
    "subset_path = data_path / f\"{size}_logs_aggregated_concurrent.csv\" if size > 0 else csv_path\n",
    "\n",
    "huawei_config = preprocessing.HuaweiPreprocessorConfig()\n",
    "huawei_config.aggregated_log_file = subset_path\n",
    "preprocessor = preprocessing.ConcurrentAggregatedLogsPreprocessor(huawei_config)\n",
    "huawei_df = preprocessor._load_log_only_data().fillna(\"\")\n",
    "huawei_df = huawei_df.sort_values(by='@timestamp').reset_index(drop=True)\n",
    "\n",
    "relevant_columns = [\n",
    "            \"Hostname\",\n",
    "            \"log_level\",\n",
    "            \"programname\",\n",
    "            \"python_module\",\n",
    "            \"http_status\",\n",
    "            \"http_method\",\n",
    "            \"@timestamp\",\n",
    "            \"fine_log_cluster_template\",\n",
    "            \"coarse_log_cluster_template\",\n",
    "            \"url_cluster_template\"\n",
    "        ]\n",
    "huawei_df.drop(labels=[x for x in huawei_df.columns if x not in relevant_columns], axis=1, inplace=True)\n",
    "huawei_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "date_format = '%Y-%m-%dT%H:%M:%S.%f000%z'\n",
    "huawei_df['@timestamp'] = huawei_df['@timestamp'].apply(lambda x: datetime.datetime.strptime(x, date_format))\n",
    "type(huawei_df['@timestamp'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Append the name of a value's column to itself\n",
    "# for column in list(huawei_df.columns):\n",
    "#     if column == '@timestamp':\n",
    "#         continue\n",
    "#     huawei_df[column].apply(lambda x: column + \"#\" + x.lower() if len(x) > 0 else \"\", inplace=True)\n",
    "# huawei_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-19 17:00:05+01:00\n",
      "2019-11-19 17:03:41.786000+01:00\n"
     ]
    }
   ],
   "source": [
    "min_dt = huawei_df['@timestamp'].iloc[0].to_pydatetime()\n",
    "max_dt = huawei_df['@timestamp'].iloc[-1].to_pydatetime()\n",
    "print(min_dt)\n",
    "print(max_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-19 00:00:00\n",
      "2019-11-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "w_top_dt = datetime.datetime.combine(min_dt.date(), datetime.time())\n",
    "w_end_dt = datetime.datetime.combine(max_dt.date(), datetime.time()) + datetime.timedelta(days = 1)\n",
    "print(w_top_dt)\n",
    "print(w_end_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of unit terms to construct DAG\n",
    "term = datetime.timedelta(minutes=5)\n",
    "\n",
    "# Length of time difference of unit terms\n",
    "diff = datetime.timedelta(minutes=5)\n",
    "\n",
    "# Bin size of discrete data for G square test\n",
    "dur = datetime.timedelta(seconds=10)\n",
    "\n",
    "# this is assuming that area is all as is default\n",
    "\n",
    "l_args = []\n",
    "top_dt = w_top_dt\n",
    "while top_dt < w_end_dt:\n",
    "    end_dt = top_dt + term\n",
    "    l_args.append((top_dt, end_dt, dur))\n",
    "    top_dt = top_dt + diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating log2event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "EvDef = namedtuple('EvDef', ['type', 'value'])\n",
    "evdict = {} # Event id -> list(datetime.datetime)\n",
    "class EventDefinitionMap: # eid -> evdef\n",
    "    def __init__(self, top_dt, end_dt):\n",
    "        self.top_dt = top_dt\n",
    "        self.end_dt = end_dt\n",
    "        self._emap = {} # key : eid, val : evdef\n",
    "        self._ermap = {} # key : evdef, val : eid\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._emap)\n",
    "\n",
    "    def _eids(self):\n",
    "        return self._emap.keys()\n",
    "\n",
    "    def _next_eid(self):\n",
    "        eid = len(self._emap)\n",
    "        while eid in self._emap:\n",
    "            eid += 1\n",
    "        else:\n",
    "            return eid\n",
    "\n",
    "    def process_row(self, columns, row):\n",
    "        row_eids = []\n",
    "        for column in columns:\n",
    "                if column == '@timestamp':\n",
    "                    continue\n",
    "                value = row[column]\n",
    "                if value == \"\":\n",
    "                    continue\n",
    "                d = {\n",
    "                    \"type\": column,\n",
    "                    \"value\": row[column],\n",
    "                }\n",
    "\n",
    "                evdef = EvDef(**d)\n",
    "\n",
    "                if evdef in self._ermap:\n",
    "                    row_eids.append(self._ermap[evdef])\n",
    "                else:\n",
    "                    eid = self._next_eid()\n",
    "                    self._emap[eid] = evdef\n",
    "                    self._ermap[evdef] = eid\n",
    "                    row_eids.append(eid)\n",
    "        return row_eids\n",
    "evmap = EventDefinitionMap(top_dt=w_top_dt, end_dt=w_end_dt)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2019-11-19 17:02:05+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:02:09+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:02:30+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:03:05+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:03:11+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:00:05+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:02:05+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:02:09+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:02:30+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:03:05+0100', tz='UTC+01:00'),\n",
       " Timestamp('2019-11-19 17:03:11+0100', tz='UTC+01:00')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for _, row in huawei_df.iterrows():\n",
    "    row_eids = evmap.process_row(huawei_df.columns, row)\n",
    "    for eid in row_eids:\n",
    "        if eid in evdict:\n",
    "            evdict[eid].append(row['@timestamp'])\n",
    "        else:\n",
    "            evdict[eid] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "700b36a561e53d43cf5db87a7727fe2d3979b618c6de3ce2a85366ffccf70fd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
